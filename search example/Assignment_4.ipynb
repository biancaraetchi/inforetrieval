{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "### Question *a*\n",
    "The component $log(1 + f_{ij})$ has the role of reducing the impact of terms with a high frequency. By using the logarithm instead of the local weight directly, frequent, but less important terms will have less 'weight' in the computation.\n",
    "\n",
    "### Question *b*\n",
    "The second component is used as a constant for all of the calculations for all documents in which the term *i* appears and it describes the entropy of the state: the more evenly-distributed a term is across the documents in which it appears, the lower the value of this second component is (less 'weight'). This component's purpose is to ensure that more important terms in the document body will score higher, which is especially important for queries looking for documents with multiple terms, since it will let the algorithm know which term to prioritize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question *c*\n",
    "*{ see code }*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question *d*\n",
    "\n",
    "Compared to TF, the log entropy weighting works better: in TF, we're accounting only for the frequency of the words used, not taking into account their relevance according to the context, while log entropy weighting also takes their spread into account. \n",
    "\n",
    "Log entropy weighting's performance is comparable to TFIDF, however, it does have a drawback: if a term is encountered too often in a set of documents, the log weighting can disregard its usages as noise by giving it a very low weight, even though it is actually relevant, compared to TFIDF."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:03:35.736399Z",
     "start_time": "2024-10-16T16:02:49.410582Z"
    }
   },
   "source": [
    "# first install the required packages\n",
    "# !pip3 install nltk\n",
    "# !pip3 install scipy\n",
    "# !pip3 install numpy\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "from inverted_index import InvertedIndex\n",
    "from utils import read_data\n",
    "inv_ind = InvertedIndex()\n",
    "documents = read_data(\"./shakespeare\")\n",
    "for d in documents:\n",
    "    inv_ind.add_document(d)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cotsi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:04:01.728638Z",
     "start_time": "2024-10-16T16:04:01.048562Z"
    }
   },
   "source": [
    "inv_ind.calcLogEntropy()\n",
    "inv_ind.generate_term_by_doc_matrix(log_entropy = True)\n",
    "results = inv_ind.search(\"scotland kings and thanes\", log_entropy=True)\n",
    "\n",
    "for r in range(10):\n",
    "    print (results[r])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.16118727379382877)\n",
      "('King Henry VI', 0.030048860936556884)\n",
      "('King Henry IV', 0.02948619616502898)\n",
      "('King Henry IV, II', 0.023764658494466812)\n",
      "('King Richard III', 0.01760253727154099)\n",
      "('King Henry V', 0.014994910138431003)\n",
      "('King John', 0.012133633289107127)\n",
      "('King Richard II', 0.012106985654825615)\n",
      "(\"All's Well that Ends Well\", 0.01119139253053665)\n",
      "('King Lear', 0.010978210515097522)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:04:05.655067Z",
     "start_time": "2024-10-16T16:04:05.004313Z"
    }
   },
   "source": [
    "inv_ind.calcTFIDF()\n",
    "inv_ind.generate_term_by_doc_matrix(tfidf=True)\n",
    "results = inv_ind.search(\"scotland kings and thanes\", tfidf=True)\n",
    "\n",
    "for r in range(10):\n",
    "    print (results[r])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.08559316237351267)\n",
      "('King Henry IV', 0.005789261723483593)\n",
      "('King Henry VI', 0.003660436049077642)\n",
      "('King Henry IV, II', 0.003121709934588564)\n",
      "('King Henry V', 0.0019193400093131976)\n",
      "('King Richard III', 0.0013431147327243318)\n",
      "('King John', 0.0007488196759316429)\n",
      "('King Richard II', 0.0006742482860831404)\n",
      "('King Henry VIII', 0.0005161221482695165)\n",
      "('The Comedy of Errors', 0.00046244490997942336)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:04:09.152032Z",
     "start_time": "2024-10-16T16:04:08.579591Z"
    }
   },
   "source": [
    "inv_ind.generate_term_by_doc_matrix()\n",
    "results = inv_ind.search(\"scotland kings and thanes\", tfidf=True)\n",
    "\n",
    "for r in range(10):\n",
    "    print (results[r])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Macbeth', 0.06342271855923712)\n",
      "('King Henry VI', 0.01072781887182939)\n",
      "('King Henry V', 0.009657775892130944)\n",
      "('King John', 0.008469965122871384)\n",
      "('King Richard II', 0.0077213170531481206)\n",
      "('King Lear', 0.006993816919843515)\n",
      "('King Henry IV', 0.006848287703722218)\n",
      "('King Henry VIII', 0.0068475238333851225)\n",
      "('King Richard III', 0.006723494450381792)\n",
      "('King Henry IV, II', 0.005135632065177295)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part B - Comparison  Metrics"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cosine Similarity"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:04:12.427839Z",
     "start_time": "2024-10-16T16:04:12.212900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Search using Term Frequency (TF)\n",
    "results_tf = inv_ind.search(\"scotland kings and thanes\", comparison='cosine', tfidf=False, log_entropy=False)\n",
    "print(\"Top 10 results for TF:\")\n",
    "for result in results_tf[:10]:  # Print top 10 results\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for TF:\n",
      "('King Henry V', 0.2659215354074205)\n",
      "('King Henry VI', 0.2617837075388672)\n",
      "('King John', 0.2472493685181954)\n",
      "('King Richard II', 0.2253953514359277)\n",
      "('King Lear', 0.20415867029886436)\n",
      "('King Henry VIII', 0.1998881836179047)\n",
      "('King Richard III', 0.18418950223762484)\n",
      "('Hamlet', 0.1241932011402115)\n",
      "(\"All's Well that Ends Well\", 0.11190811971898096)\n",
      "('King Henry IV', 0.10791586179996365)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:04:16.806298Z",
     "start_time": "2024-10-16T16:04:16.231529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Search using TF-IDF\n",
    "inv_ind.calcTFIDF()\n",
    "results_tfidf = inv_ind.search(\"scotland kings and thanes\", comparison='cosine', tfidf=True, log_entropy=False)\n",
    "print(\"Top 10 results for TF-IDF:\")\n",
    "for result in results_tfidf[:10]:  # Print top 10 results\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for TF-IDF:\n",
      "('Macbeth', 0.06342271855923712)\n",
      "('King Henry VI', 0.01072781887182939)\n",
      "('King Henry V', 0.009657775892130944)\n",
      "('King John', 0.008469965122871384)\n",
      "('King Richard II', 0.0077213170531481206)\n",
      "('King Lear', 0.006993816919843515)\n",
      "('King Henry IV', 0.006848287703722218)\n",
      "('King Henry VIII', 0.0068475238333851225)\n",
      "('King Richard III', 0.006723494450381792)\n",
      "('King Henry IV, II', 0.005135632065177295)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:04:20.986167Z",
     "start_time": "2024-10-16T16:04:20.435406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Search using Log-Entropy\n",
    "inv_ind.calcLogEntropy()\n",
    "results_log_entropy = inv_ind.search(\"scotland kings and thanes\", comparison='cosine', tfidf=False, log_entropy=True)\n",
    "print(\"Top 10 results for Log-Entropy:\")\n",
    "for result in results_log_entropy[:10]:  # Print top 10 results\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for Log-Entropy:\n",
      "('King Henry V', 0.09750612858021179)\n",
      "('King Henry VI', 0.09685636836860602)\n",
      "('King John', 0.09029725585555785)\n",
      "('King Richard II', 0.0823160109133527)\n",
      "('Macbeth', 0.07794364227080823)\n",
      "('King Lear', 0.07456022151882818)\n",
      "('King Henry VIII', 0.0730006089270169)\n",
      "('King Richard III', 0.0675614568558054)\n",
      "('Hamlet', 0.04535625440051694)\n",
      "('King Henry IV', 0.04165185879463941)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    "
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Euclidean"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:52:47.127986Z",
     "start_time": "2024-10-16T18:52:46.435946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Search using Euclidean distance for TF\n",
    "results_euclidean_tf = inv_ind.search(\"scotland kings and thanes\", comparison='euclidean', tfidf=False,\n",
    "                                      log_entropy=False)\n",
    "print(\"Top 10 results for TF using Euclidean distance:\")\n",
    "for result in results_euclidean_tf[:10]:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n",
      "Top 10 results for TF using Euclidean distance:\n",
      "('King Richard III', 977.6604727613774)\n",
      "('Hamlet', 971.3871524783515)\n",
      "('Antony and Cleopatra', 964.5123120002149)\n",
      "('The Merry Wives of Windsor', 960.9146684279515)\n",
      "('King Henry VI', 919.2197778551113)\n",
      "('Othello', 895.3379250316609)\n",
      "('King Lear', 876.3121589935861)\n",
      "('Romeo and Juliet', 845.559578031022)\n",
      "('Troilus and Cressida', 825.5434573661158)\n",
      "('Twelfth Night', 811.7604326400739)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:52:57.491832Z",
     "start_time": "2024-10-16T18:52:57.051012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Similarly, test for TF-IDF\n",
    "results_euclidean_tfidf = inv_ind.search(\"scotland kings and thanes\", comparison='euclidean', tfidf=True, log_entropy=False)\n",
    "print(\"Top 10 results for TF-IDF using Euclidean distance:\")\n",
    "for result in results_euclidean_tfidf[:10]:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for TF-IDF using Euclidean distance:\n",
      "('King Richard III', 977.9591793885204)\n",
      "('Hamlet', 971.5919516780838)\n",
      "('Antony and Cleopatra', 964.5402306478967)\n",
      "('The Merry Wives of Windsor', 960.9235444334813)\n",
      "('King Henry VI', 919.637168631695)\n",
      "('Othello', 895.3464236439547)\n",
      "('King Lear', 876.6451687762146)\n",
      "('Romeo and Juliet', 845.5707529007785)\n",
      "('Troilus and Cressida', 825.5638179316403)\n",
      "('Twelfth Night', 811.7720727896404)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:53:02.130499Z",
     "start_time": "2024-10-16T18:53:01.797641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# And for Log-Entropy\n",
    "results_euclidean_log = inv_ind.search(\"scotland kings and thanes\", comparison='euclidean', tfidf=False, log_entropy=True)\n",
    "print(\"Top 10 results for Log-Entropy using Euclidean distance:\")\n",
    "for result in results_euclidean_log[:10]:\n",
    "    print(result)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for Log-Entropy using Euclidean distance:\n",
      "('King Richard III', 977.9226688691896)\n",
      "('Hamlet', 971.5637014074697)\n",
      "('Antony and Cleopatra', 964.5299537977396)\n",
      "('The Merry Wives of Windsor', 960.9151805823741)\n",
      "('King Henry VI', 919.5922047196742)\n",
      "('Othello', 895.3375519314969)\n",
      "('King Lear', 876.6030548455894)\n",
      "('Romeo and Juliet', 845.5611371442204)\n",
      "('Troilus and Cressida', 825.5530604681885)\n",
      "('Twelfth Night', 811.7620566697037)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pearson Correlation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:53:08.055355Z",
     "start_time": "2024-10-16T18:53:07.468029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Search using Pearson correlation for TF\n",
    "results_pearson_tf = inv_ind.search(\"scotland kings and thanes\", comparison='pearson', tfidf=False, log_entropy=False)\n",
    "print(\"Top 10 results for TF using Pearson correlation:\")\n",
    "for result in results_pearson_tf[:10]:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for TF using Pearson correlation:\n",
      "('King Henry V', np.float64(0.2672845942826732))\n",
      "('King Henry VI', np.float64(0.26227119702889495))\n",
      "('King John', np.float64(0.2481135003838783))\n",
      "('King Richard II', np.float64(0.22584782757536365))\n",
      "('King Lear', np.float64(0.2043933444230004))\n",
      "('King Henry VIII', np.float64(0.20024547381710653))\n",
      "('King Richard III', np.float64(0.1842492444798212))\n",
      "('Hamlet', np.float64(0.12365428106716204))\n",
      "(\"All's Well that Ends Well\", np.float64(0.11126105942895444))\n",
      "('King Henry IV', np.float64(0.10723385272720164))\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:53:12.743317Z",
     "start_time": "2024-10-16T18:53:12.446676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Similarly, test for TF-IDF and Log-Entropy\n",
    "results_pearson_tfidf = inv_ind.search(\"scotland kings and thanes\", comparison='pearson', tfidf=True, log_entropy=False)\n",
    "print(\"Top 10 results for TF-IDF using Pearson correlation:\")\n",
    "for result in results_pearson_tfidf[:10]:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for TF-IDF using Pearson correlation:\n",
      "('Macbeth', np.float64(0.06267945775801861))\n",
      "('King Henry VI', np.float64(0.00959778135880493))\n",
      "('King Henry V', np.float64(0.008234140901230032))\n",
      "('King John', np.float64(0.00712077605785567))\n",
      "('King Richard II', np.float64(0.006439790249779128))\n",
      "('King Lear', np.float64(0.0057114947532060124))\n",
      "('King Henry IV', np.float64(0.005528118282967445))\n",
      "('King Henry VIII', np.float64(0.005473723954416025))\n",
      "('King Richard III', np.float64(0.005426662847842688))\n",
      "('King Henry IV, II', np.float64(0.003735769671781538))\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:53:27.228226Z",
     "start_time": "2024-10-16T18:53:26.836713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "results_pearson_log = inv_ind.search(\"scotland kings and thanes\", comparison='pearson', tfidf=False, log_entropy=True)\n",
    "print(\"Top 10 results for Log-Entropy using Pearson correlation:\")\n",
    "for result in results_pearson_log[:10]:\n",
    "    print(result)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for Log-Entropy using Pearson correlation:\n",
      "('King Henry V', np.float64(0.09695676303218753))\n",
      "('King Henry VI', np.float64(0.09621744517615671))\n",
      "('King John', np.float64(0.08963088114547306))\n",
      "('King Richard II', np.float64(0.08155756549170035))\n",
      "('Macbeth', np.float64(0.07714192026705806))\n",
      "('King Lear', np.float64(0.07372708039450968))\n",
      "('King Henry VIII', np.float64(0.07214421233044967))\n",
      "('King Richard III', np.float64(0.06665847324506251))\n",
      "('Hamlet', np.float64(0.04424579001150782))\n",
      "('King Henry IV', np.float64(0.040479852917600215))\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Spearman Correlation "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:53:33.420273Z",
     "start_time": "2024-10-16T18:53:32.393027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Search using Spearman correlation for TF\n",
    "results_spearman_tf = inv_ind.search(\"scotland kings and thanes\", comparison='spearman', tfidf=False, log_entropy=False)\n",
    "print(\"Top 10 results for TF using Spearman correlation:\")\n",
    "for result in results_spearman_tf[:10]:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for TF using Spearman correlation:\n",
      "('Macbeth', np.float64(0.03532054253793877))\n",
      "('King Henry VI', np.float64(0.02056523596193464))\n",
      "('King Henry IV', np.float64(0.0197997185617009))\n",
      "('King Henry IV, II', np.float64(0.018928390837357485))\n",
      "('King Richard III', np.float64(0.017342569082006154))\n",
      "('King Henry V', np.float64(0.01604597635712879))\n",
      "('Venus and Adonis', np.float64(0.009664535381060973))\n",
      "('The Two Gentlemen of Verona', np.float64(0.009040721972581985))\n",
      "('Julius Caesar', np.float64(0.0088873026121942))\n",
      "(\"A Midsummer Night's Dream\", np.float64(0.008704179445923764))\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:53:37.585428Z",
     "start_time": "2024-10-16T18:53:36.935100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Similarly, test for TF-IDF and Log-Entropy\n",
    "results_spearman_tfidf = inv_ind.search(\"scotland kings and thanes\", comparison='spearman', tfidf=True, log_entropy=False)\n",
    "print(\"Top 10 results for TF-IDF using Spearman correlation:\")\n",
    "for result in results_spearman_tfidf[:10]:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for TF-IDF using Spearman correlation:\n",
      "('Macbeth', np.float64(0.03532053880834422))\n",
      "('King Henry VI', np.float64(0.020563846351680876))\n",
      "('King Henry IV', np.float64(0.01979836767300667))\n",
      "('King Henry IV, II', np.float64(0.01892705235236277))\n",
      "('King Richard III', np.float64(0.017341224061222318))\n",
      "('King Henry V', np.float64(0.016044670572755822))\n",
      "('Venus and Adonis', np.float64(0.009663069321508363))\n",
      "('The Two Gentlemen of Verona', np.float64(0.009039307964380752))\n",
      "('Julius Caesar', np.float64(0.008885895440319353))\n",
      "(\"A Midsummer Night's Dream\", np.float64(0.008702770591046464))\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:53:41.871970Z",
     "start_time": "2024-10-16T18:53:41.134744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_spearman_log = inv_ind.search(\"scotland kings and thanes\", comparison='spearman', tfidf=False, log_entropy=True)\n",
    "print(\"Top 10 results for Log-Entropy using Spearman correlation:\")\n",
    "for result in results_spearman_log[:10]:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for Log-Entropy using Spearman correlation:\n",
      "('Macbeth', np.float64(0.03532053880834422))\n",
      "('King Henry VI', np.float64(0.020563846351680876))\n",
      "('King Henry IV', np.float64(0.01979836767300667))\n",
      "('King Henry IV, II', np.float64(0.01892705235236277))\n",
      "('King Richard III', np.float64(0.017341224061222318))\n",
      "('King Henry V', np.float64(0.016044670572755822))\n",
      "('Venus and Adonis', np.float64(0.009663069321508363))\n",
      "('The Two Gentlemen of Verona', np.float64(0.009039307964380752))\n",
      "('Julius Caesar', np.float64(0.008885895440319353))\n",
      "(\"A Midsummer Night's Dream\", np.float64(0.008702770591046464))\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Jaccard Similarity"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:53:46.891587Z",
     "start_time": "2024-10-16T18:53:46.330681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Search using Jaccard similarity for TF\n",
    "results_jaccard_tf = inv_ind.search(\"scotland kings and thanes\", comparison='jaccard', tfidf=False, log_entropy=False)\n",
    "print(\"Top 10 results for TF using Jaccard similarity:\")\n",
    "for result in results_jaccard_tf[:10]:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for TF using Jaccard similarity:\n",
      "('Macbeth', 0.0010913059294288831)\n",
      "('King Henry VI', 0.0006894174422612892)\n",
      "('King Henry IV', 0.0006232471174820816)\n",
      "('King Richard III', 0.0006127450980392157)\n",
      "('King Henry IV, II', 0.0006022282445046673)\n",
      "('King Henry V', 0.000543773790103317)\n",
      "('The Comedy of Errors', 0.0004723665564478035)\n",
      "('Venus and Adonis', 0.000468384074941452)\n",
      "('The Two Gentlemen of Verona', 0.000445632798573975)\n",
      "('Julius Caesar', 0.0004306632213608958)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:53:50.792168Z",
     "start_time": "2024-10-16T18:53:50.193970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Similarly, test for TF-IDF and Log-Entropy\n",
    "results_jaccard_tfidf = inv_ind.search(\"scotland kings and thanes\", comparison='jaccard', tfidf=True, log_entropy=False)\n",
    "print(\"Top 10 results for TF-IDF using Jaccard similarity:\")\n",
    "for result in results_jaccard_tfidf[:10]:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for TF-IDF using Jaccard similarity:\n",
      "('Macbeth', 0.0010913059294288831)\n",
      "('King Henry VI', 0.0006894174422612892)\n",
      "('King Henry IV', 0.0006232471174820816)\n",
      "('King Richard III', 0.0006127450980392157)\n",
      "('King Henry IV, II', 0.0006022282445046673)\n",
      "('King Henry V', 0.000543773790103317)\n",
      "('The Comedy of Errors', 0.0004723665564478035)\n",
      "('Venus and Adonis', 0.000468384074941452)\n",
      "('The Two Gentlemen of Verona', 0.000445632798573975)\n",
      "('Julius Caesar', 0.0004306632213608958)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:53:54.334022Z",
     "start_time": "2024-10-16T18:53:53.909992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_jaccard_log = inv_ind.search(\"scotland kings and thanes\", comparison='jaccard', tfidf=False, log_entropy=True)\n",
    "print(\"Top 10 results for Log-Entropy using Jaccard similarity:\")\n",
    "for result in results_jaccard_log[:10]:\n",
    "    print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 results for Log-Entropy using Jaccard similarity:\n",
      "('Macbeth', 0.0010913059294288831)\n",
      "('King Henry VI', 0.0006894174422612892)\n",
      "('King Henry IV', 0.0006232471174820816)\n",
      "('King Richard III', 0.0006127450980392157)\n",
      "('King Henry IV, II', 0.0006022282445046673)\n",
      "('King Henry V', 0.000543773790103317)\n",
      "('The Comedy of Errors', 0.0004723665564478035)\n",
      "('Venus and Adonis', 0.000468384074941452)\n",
      "('The Two Gentlemen of Verona', 0.000445632798573975)\n",
      "('Julius Caesar', 0.0004306632213608958)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comparison of Similarity Metrics for Document Retrieval\n",
    "\n",
    "## Introduction\n",
    "This report explores the effectiveness of various comparison metrics in determining the relevance of documents to a query. We tested **Cosine Similarity**, **Euclidean Distance**, **Pearson Correlation**, **Spearman Correlation**, and **Jaccard Similarity** using the Shakespeare dataset and three document representation techniques: **Term Frequency (TF)**, **TF-IDF**, and **Log-Entropy**.\n",
    "\n",
    "## Methodology\n",
    "We implemented and evaluated each similarity metric for its ability to rank the top 10 most relevant documents for the query \"Scotland kings and thanes.\" The query's relevance was measured based on how appropriate and consistent the documents were with the search term across various metrics and document representations.\n",
    "\n",
    "### Evaluation Criteria\n",
    "The effectiveness of each metric is determined based on:\n",
    "- **Relevance of results**: Whether the returned documents relate closely to the query.\n",
    "- **Consistency**: How stable the results are across different document representations (TF, TF-IDF, Log-Entropy).\n",
    "- **Scalability**: The computational complexity and scalability of each metric.\n",
    "\n",
    "## Analysis of Results\n",
    "\n",
    "### 1. Cosine Similarity (Baseline)\n",
    "Cosine similarity measures the angle between two vectors, which is effective for comparing text data.\n",
    "- **Relevance**: Cosine similarity returned highly relevant documents, especially for the term \"King Henry\" across multiple plays in the dataset. This aligns well with the search query focusing on \"kings and thanes.\"\n",
    "- **Consistency**: Results were consistent across TF, TF-IDF, and Log-Entropy. With minor variations, the same key documents appeared across different representations.\n",
    "- **Scalability**: Cosine similarity is computationally efficient, making it suitable for large datasets. Overall, it performed well as a baseline.\n",
    "\n",
    "### 2. Euclidean Distance\n",
    "Euclidean distance measures the straight-line distance between two points in the vector space.\n",
    "- **Relevance**: The results were less relevant compared to cosine similarity. While some key documents like \"Hamlet\" and \"King Richard\" appeared, other plays like \"The Merry Wives of Windsor\" and \"Antony and Cleopatra\" were returned, which are not closely related to the query.\n",
    "- **Consistency**: The results varied considerably across TF, TF-IDF, and Log-Entropy. For instance, \"Twelfth Night\" appeared in TF results but not in TF-IDF or Log-Entropy.\n",
    "- **Scalability**: Euclidean distance is sensitive to document length, leading to poor performance in high-dimensional spaces like text data. It is not a good choice for document retrieval.\n",
    "\n",
    "### 3. Pearson Correlation\n",
    "Pearson correlation measures the linear correlation between two vectors.\n",
    "- **Relevance**: Pearson correlation produced results similar to cosine similarity, with relevant documents like \"King Henry V\" and \"King Richard II\" appearing consistently. However, the overall relevance was slightly lower compared to cosine similarity.\n",
    "- **Consistency**: The results were fairly consistent across all representations, but slight variations were observed.\n",
    "- **Scalability**: Pearson correlation, like cosine similarity, is computationally feasible and works well for text comparisons. However, it did not outperform cosine similarity in relevance.\n",
    "\n",
    "### 4. Spearman Correlation\n",
    "Spearman correlation measures the rank correlation between two vectors, making it more robust to non-linear relationships.\n",
    "- **Relevance**: Spearman correlation returned relevant results like \"Macbeth\" and various \"King Henry\" plays, which are very closely aligned with the query. However, lower-ranked results included less relevant documents such as \"Julius Caesar.\"\n",
    "- **Consistency**: The results were relatively consistent across TF, TF-IDF, and Log-Entropy, with only slight variations.\n",
    "- **Scalability**: Spearman correlation is computationally heavier than Pearson and cosine similarity due to the ranking mechanism. While it produced relevant results, it did not outperform cosine similarity or Pearson correlation.\n",
    "\n",
    "### 5. Jaccard Similarity\n",
    "Jaccard similarity measures the overlap between two sets, which in the case of text, compares word co-occurrence.\n",
    "- **Relevance**: Jaccard similarity returned less relevant documents compared to other metrics. The top result, \"Macbeth,\" was relevant, but other documents like \"The Comedy of Errors\" and \"Venus and Adonis\" were not closely related to the query.\n",
    "- **Consistency**: The results were fairly consistent across all document representations, but the relevance was consistently lower.\n",
    "- **Scalability**: Jaccard similarity is not well-suited for high-dimensional spaces like text data. It performed poorly in terms of relevance and is not recommended for document retrieval tasks.\n",
    "\n",
    "## Conclusion\n",
    "Among the five metrics tested, **Cosine Similarity** proved to be the most effective in returning relevant and consistent results for the query. It outperformed other metrics like **Euclidean Distance**, which suffered from poor relevance, and **Jaccard Similarity**, which struggled to capture meaningful document relationships. **Pearson Correlation** and **Spearman Correlation** also performed well, though they did not surpass Cosine Similarity in terms of relevance and efficiency.\n",
    "\n",
    "For future implementations, Cosine Similarity is recommended due to its balance of relevance, consistency, and scalability, especially for large text datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
